from dotenv import load_dotenv
import streamlit as st
import os
from PIL import Image
from gtts import gTTS  # For generating audio
import io
import google.generativeai as genai
from transformers import BlipProcessor, BlipForConditionalGeneration

# Load environment variables
load_dotenv()

# Configure Google API key
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

# Initialize image captioning model (Hugging Face's BLIP model)
processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")

# Function to generate image description
def generate_image_description(image):
    inputs = processor(images=image, return_tensors="pt")
    outputs = model.generate(**inputs)
    return processor.decode(outputs[0], skip_special_tokens=True)

# Function to interact with the Gemini model
def get_gemini_response(image_description):
    try:
        model = genai.GenerativeModel('gemini-1.5-flash')
        prompt = (
            f"Describe the cultural or heritage significance of the following place: {image_description}. "
            "Provide a brief introduction about the place, followed by an interesting and unique story or fact about it."
        )
        print("Prompt being sent to Gemini:", prompt)
        response = model.generate_content([prompt])
        
        if response and response.generations:
            return response.generations[0].text
        else:
            return "No response generated by the model."
    except Exception as e:
        print("Error during API call:", e)
        return "An error occurred while generating the response."

# Function to generate audio from text
def text_to_audio(text):
    tts = gTTS(text, lang="en")
    audio_buffer = io.BytesIO()
    tts.write_to_fp(audio_buffer)
    audio_buffer.seek(0)
    return audio_buffer

# Streamlit app setup
st.set_page_config(page_title="Cultural Heritage Explorer")

st.header("Cultural Heritage Explorer")
st.subheader("Upload an image of a cultural or heritage site and learn about its significance!")

# Image upload section
uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    image = Image.open(uploaded_file)
    st.image(image, caption="Uploaded Image.", use_column_width=True)

    # Submit button
    submit = st.button("Tell me about the image")

    if submit:
        with st.spinner("Analyzing the image and generating response..."):
            # Generate image description
            image_description = generate_image_description(image)
            st.subheader("Generated Image Description")
            st.write(image_description)

            # Generate response using Gemini
            gemini_response = get_gemini_response(image_description)

            # Separate introduction and story (assuming response structure is appropriate)
            try:
                intro, story = gemini_response.split("\n\n", 1)
            except ValueError:
                intro = gemini_response
                story = ""

            # Display text
            st.subheader("Introduction")
            st.write(intro)
            st.subheader("Interesting Story or Fact")
            st.write(story)

            # Generate audio
            if story:
                audio_buffer = text_to_audio(story)
                st.audio(audio_buffer, format="audio/mp3", start_time=0)
            else:
                st.warning("Could not generate an interesting story or fact.")
else:
    st.info("Please upload an image of a cultural or heritage site to get started!")
